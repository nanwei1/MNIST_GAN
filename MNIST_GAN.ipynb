{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 32\n",
    "hidden1_size = 64\n",
    "hidden2_size = 128\n",
    "image_size = 784\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "sample_dir = 'samples'\n",
    "save_dir = 'save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor()])\n",
    "\n",
    "# MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(root='./data/',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1b43ae3828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs, lbls = next(iter(data_loader))\n",
    "imgs[0].data.shape\n",
    "print(imgs.data.min())\n",
    "print(imgs.data.max())\n",
    "plt.imshow(imgs[0].data.reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden2_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden2_size, hidden1_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden1_size, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden1_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden1_size, hidden2_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden2_size, image_size),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=5e-4)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] took 19.731241464614868 seconds\n",
      "Epoch [2/30] took 25.713005542755127 seconds\n",
      "Epoch [3/30] took 21.787495851516724 seconds\n",
      "Epoch [4/30] took 22.809000730514526 seconds\n",
      "Epoch [5/30] took 24.66292929649353 seconds\n",
      "Epoch [6/30] took 24.88949751853943 seconds\n",
      "Epoch [7/30] took 20.7968692779541 seconds\n",
      "Epoch [8/30] took 19.66516137123108 seconds\n",
      "Epoch [9/30] took 19.494091033935547 seconds\n",
      "Epoch [10/30] took 19.90772819519043 seconds\n",
      "Epoch [11/30] took 25.21996569633484 seconds\n",
      "Epoch [12/30] took 26.50868535041809 seconds\n",
      "Epoch [13/30] took 29.29830527305603 seconds\n",
      "Epoch [14/30] took 29.206934213638306 seconds\n",
      "Epoch [15/30] took 25.179628610610962 seconds\n",
      "Epoch [16/30] took 23.997515201568604 seconds\n",
      "Epoch [17/30] took 26.714616060256958 seconds\n",
      "Epoch [18/30] took 27.44491195678711 seconds\n",
      "Epoch [19/30] took 24.039395093917847 seconds\n",
      "Epoch [20/30] took 24.355393648147583 seconds\n",
      "Epoch [21/30] took 30.30539059638977 seconds\n",
      "Epoch [22/30] took 30.071666479110718 seconds\n",
      "Epoch [23/30] took 25.137555599212646 seconds\n",
      "Epoch [24/30] took 30.28367853164673 seconds\n",
      "Epoch [25/30] took 29.80913233757019 seconds\n",
      "Epoch [26/30] took 29.72523546218872 seconds\n",
      "Epoch [27/30] took 30.36133599281311 seconds\n",
      "Epoch [28/30] took 30.16550302505493 seconds\n",
      "Epoch [29/30] took 29.33010196685791 seconds\n",
      "Epoch [30/30] took 31.13629674911499 seconds\n"
     ]
    }
   ],
   "source": [
    "# Statistics to be saved\n",
    "d_losses = np.zeros(num_epochs)\n",
    "g_losses = np.zeros(num_epochs)\n",
    "real_scores = np.zeros(num_epochs)\n",
    "fake_scores = np.zeros(num_epochs)\n",
    "\n",
    "# Start training\n",
    "start_time = time.time()\n",
    "total_step = len(data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.view(images.size(0), -1)\n",
    "#         images = Variable(images)\n",
    "        # Create the labels which are later used as input for the BCE loss\n",
    "        real_labels = torch.ones(images.size(0), 1)\n",
    "#         real_labels = Variable(real_labels)\n",
    "        fake_labels = torch.zeros(images.size(0), 1)\n",
    "#         fake_labels = Variable(fake_labels)\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                      Train the discriminator                       #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        reset_grad()\n",
    "        z = torch.randn(images.size(0), latent_size)\n",
    "#         z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # If D is trained so well, then don't update\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        # ================================================================== #\n",
    "        #                        Train the generator                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        reset_grad()\n",
    "        z = torch.randn(images.size(0), latent_size)\n",
    "#         z = Variable(z)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        # if G is trained so well, then don't update\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        # =================================================================== #\n",
    "        #                          Update Statistics                          #\n",
    "        # =================================================================== #\n",
    "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.item()*(1./(i+1.))\n",
    "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.item()*(1./(i+1.))\n",
    "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().item()*(1./(i+1.))\n",
    "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().item()*(1./(i+1.))\n",
    "        \n",
    "    print('Epoch [{}/{}] took {} seconds'.format(epoch+1, num_epochs, time.time()-epoch_start_time))\n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.view(images.size(0), 1, 28, 28)\n",
    "        save_image(images.data, os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(fake_images.data, os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "    \n",
    "    # Save and plot Statistics\n",
    "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
    "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
    "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
    "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
    "    \n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([0, num_epochs + 1])\n",
    "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
    "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim([0, num_epochs + 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
    "    plt.close()\n",
    "\n",
    "    # Save model at checkpoints\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
    "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no attribute 'xlabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-96a86c80334c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dsaf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'xlabel'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
    "np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
    "np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
    "np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, num_epochs + 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
    "plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_dir, 'loss.png'))\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([0, num_epochs + 1])\n",
    "ax.set_ylim([0, 1])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
    "plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(save_dir, 'accuracy.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
